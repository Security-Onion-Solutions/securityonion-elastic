#!/bin/bash
#
# Copyright 2014,2015,2016,2017,2018,2019,2020 Security Onion Solutions, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

. /usr/sbin/so-elastic-common

. /etc/nsm/securityonion.conf

LOGSTASH_CONFD="/etc/logstash/conf.d"
CUSTOM_CONF="/etc/logstash/custom"
CUSTOM_INGEST="/etc/elasticsearch/custom"
LOG="/var/log/logstash/logstash.log"

#########################################
# Options
#########################################
usage()
{
cat <<EOF
Start Logtash
  Options:
  -h         This message
  -v         Tail the Logstash log after starting

EOF
}

while getopts "hv" OPTION
do
        case $OPTION in
                h)
                        usage
                        exit 0
                        ;;
                v)
                        TAIL=1
                        ;;
                *)
                        usage
                        exit 0
                        ;;
        esac
done


if [ "$LOGSTASH_ENABLED" = "yes" ]; then
        echo -n "so-logstash: "
        if docker ps | grep -q so-logstash; then
                echo "Already started!"
        else
		docker rm so-logstash >/dev/null 2>&1

		LS_JVM="/etc/logstash/jvm.options"
		# Add Xss option for Java Execution Engine if necessary
		if ! grep -q "Xss" $LS_JVM; then
			echo "" >> $LS_JVM
			echo "# Avoid StackOverflowError when enabling Java Execution Engine" >> $LS_JVM
			echo "# https://github.com/elastic/logstash/issues/10131" >> $LS_JVM
			echo "-Xss16M" >> $LS_JVM
		fi
		# Add -Djruby.regexp.interruptible=true option if necessary
		if ! grep -q "Djruby.regexp.interruptible=true" $LS_JVM; then
			echo "" >> $LS_JVM
			echo "# Make sure joni regexp interruptability is enabled" >> $LS_JVM
			echo "-Djruby.regexp.interruptible=true" >> $LS_JVM
		fi
		# Remove UseParNewGC option if necessary
		if grep -q "XX:+UseParNewGC" $LS_JVM; then
			sed -i '/-XX:+UseParNewGC/d' $LS_JVM
		fi

                if [ -d $CUSTOM_CONF ]; then
			rsync $CUSTOM_CONF/*.conf /etc/logstash/conf.d >/dev/null 2>&1
                        rsync $CUSTOM_CONF/*.json /etc/logstash/ >/dev/null 2>&1
		else
			mkdir $CUSTOM_CONF
		fi

                if [ -d $CUSTOM_INGEST ]; then
			rsync $CUSTOM_INGEST/* /etc/elasticsearch/ingest >/dev/null 2>&1
		else
			mkdir $CUSTOM_INGEST
		fi

		if [ "$FREQ_SERVER_ENABLED" = "yes" ]; then
			ln -sf ../conf.d.available/8502_postprocess_freq_analysis_bro_dns.conf /etc/logstash/conf.d/8502_postprocess_freq_analysis_bro_dns.conf
			ln -sf ../conf.d.available/8503_postprocess_freq_analysis_bro_http.conf /etc/logstash/conf.d/8503_postprocess_freq_analysis_bro_http.conf
			ln -sf ../conf.d.available/8504_postprocess_freq_analysis_bro_ssl.conf /etc/logstash/conf.d/8504_postprocess_freq_analysis_bro_ssl.conf
			ln -sf ../conf.d.available/8505_postprocess_freq_analysis_bro_x509.conf /etc/logstash/conf.d/8505_postprocess_freq_analysis_bro_x509.conf
                fi
                if [ "$FREQ_SERVER_ENABLED" = "no" ]; then
                        rm -f /etc/logstash/conf.d/*_postprocess_freq_analysis_*.conf
                fi
                if [ "$DOMAIN_STATS_ENABLED" = "yes" ]; then
			ln -sf ../conf.d.available/8007_postprocess_dns_top1m_tagging.conf /etc/logstash/conf.d/8007_postprocess_dns_top1m_tagging.conf
			ln -sf ../conf.d.available/8008_postprocess_dns_whois_age.conf /etc/logstash/conf.d/8008_postprocess_dns_whois_age.conf
                fi
                if [ "$DOMAIN_STATS_ENABLED" = "no" ]; then
                        rm -f /etc/logstash/conf.d/8007_postprocess_dns_top1m_tagging.conf
                        rm -f /etc/logstash/conf.d/8008_postprocess_dns_whois_age.conf
                fi

                if [ "$LOGSTASH_MINIMAL" = "yes" ]; then
			# move parsing from logstash to elasticsearch ingest node

			# add pipelines to elasticsearch
			/usr/sbin/so-elasticsearch-pipelines > /var/log/nsm/so-elasticsearch-pipelines.log 2>/dev/null

			# create a new config directory for minimal config
			LOGSTASH_CONFD="/etc/logstash/conf.d.minimal/"
			mkdir -p $LOGSTASH_CONFD
			if ! [ -f $LOGSTASH_CONFD/0000_input_syslogng.conf ]; then
				ln -sf ../conf.d.available/0000_input_syslogng.conf 				$LOGSTASH_CONFD/0000_input_syslogng.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/1001_preprocess_syslogng.conf ]; then
				ln -sf ../conf.d.available/1001_preprocess_syslogng.conf 			$LOGSTASH_CONFD/1001_preprocess_syslogng.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/8999_postprocess_rename_type.conf ]; then
				ln -sf ../conf.d.available/8999_postprocess_rename_type.conf 			$LOGSTASH_CONFD/8999_postprocess_rename_type.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/9034_output_syslog.conf ]; then
				ln -sf ../conf.d.available/9034_output_syslog.conf 				$LOGSTASH_CONFD/9034_output_syslog.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/9000_output_bro.conf ]; then
				cp /etc/logstash/conf.d.available/9000_output_bro.conf 				$LOGSTASH_CONFD/9000_output_bro.conf
		                sed -i 's|elasticsearch {|elasticsearch {\n      pipeline => "%{event_type}"|' 	$LOGSTASH_CONFD/9000_output_bro.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/9033_output_snort.conf ]; then
				cp /etc/logstash/conf.d.available/9033_output_snort.conf 			$LOGSTASH_CONFD/9033_output_snort.conf
		                sed -i 's|elasticsearch {|elasticsearch {\n      pipeline => "%{event_type}"|' 	$LOGSTASH_CONFD/9033_output_snort.conf
			fi
			if ! [ -f $LOGSTASH_CONFD/9600_output_ossec.conf ]; then
				cp /etc/logstash/conf.d.available/9600_output_ossec.conf			$LOGSTASH_CONFD/9600_output_ossec.conf
		                sed -i 's|elasticsearch {|elasticsearch {\n      pipeline => "%{event_type}"|' 	$LOGSTASH_CONFD/9600_output_ossec.conf
			fi
		fi				

                if [ "$LOGSTASH_OUTPUT_INGEST" = "yes" ]; then
			# move parsing from logstash to elasticsearch ingest node

			# add pipelines to elasticsearch
			/usr/sbin/so-elasticsearch-pipelines > /var/log/nsm/so-elasticsearch-pipelines.log 2>/dev/null

			# logstash just needs inputs and an ingest node pipeline output
			# create a new config directory for these files
			LOGSTASH_CONFD="/etc/logstash/conf.d.ingest.output/"
			mkdir -p $LOGSTASH_CONFD

			INPUT_SGUILD_NIDS=$LOGSTASH_CONFD/0000_input_sguild_nids.conf
			if ! [ -f $INPUT_SGUILD_NIDS ]; then
cat << EOF > $INPUT_SGUILD_NIDS
input {
	file {
		path => "/var/log/nsm/securityonion/sguild.log"
		type => "sguild_nids"
	    	tags => ["nids", "import"]
	}
}
EOF
			fi

			INPUT_IMPORT=$LOGSTASH_CONFD/0007_input_import.conf
			if ! [ -f $INPUT_IMPORT ]; then
				# copy 0007_input_import.conf but exclude last 7 lines
				head --lines=-7 /etc/logstash/conf.d.available/0007_input_import.conf > $INPUT_IMPORT
			fi

			OUTPUT_INGEST=$LOGSTASH_CONFD/9002_output_import.conf
			if ! [ -f $OUTPUT_INGEST ]; then
cat << EOF > $OUTPUT_INGEST	
output {
    elasticsearch {
      hosts => elasticsearch
      index => "logstash-import-%{+YYYY.MM.dd}"
      pipeline => "%{type}"
      template_name => "logstash-*"
      template => "/logstash-template.json"
      template_overwrite => true
    }
}
EOF
			fi
		fi

                if [ "$LOGSTASH_INPUT_REDIS" = "yes" ]; then
			# this is a storage node consuming from redis
			# need to add an input if it doesn't already exist
			INPUT_REDIS_CONF="$LOGSTASH_CONFD/0900_input_redis.conf"
			if ! [ -f $INPUT_REDIS_CONF ]; then
cat << EOF >> $INPUT_REDIS_CONF
input {
	redis {
		host => '172.18.0.1'
		data_type => 'list'
		key => 'logstash:redis'
		type => 'redis-input'
		batch_count => 125
		threads => 1
	}
}
EOF
			fi
		else
			rm -f $INPUT_REDIS_CONF
		fi

                if [ "$LOGSTASH_OUTPUT_REDIS" = "yes" ]; then
			# this is a master server outputting to redis
			# logstash just needs inputs and a redis output
			# create a new config directory for these files
			LOGSTASH_CONFD="/etc/logstash/conf.d.redis.output/"
			mkdir -p $LOGSTASH_CONFD
			OUTPUT_REDIS_CONF="$LOGSTASH_CONFD/9999_output_redis.conf"

			# create a symbolic link for each input
			cd /etc/logstash/conf.d.available
			for i in 0???_input_*.conf; do
				if ! [ -f /etc/logstash/conf.d.redis.output/$i ]; then
					ln -sf ../conf.d.available/$i /etc/logstash/conf.d.redis.output/$i
				fi
			done
			cd - >/dev/null

			# create the redis output if it doesn't already exist
			if ! [ -f $OUTPUT_REDIS_CONF ]; then
cat << EOF >> $OUTPUT_REDIS_CONF
output {
	redis {
		host => '172.18.0.1'
		data_type => 'list'
		key => 'logstash:redis'
		congestion_interval => 1
		congestion_threshold => 50000000
		batch => true
		batch_events => 50
	}
}
EOF
			fi

			# now configure redis
			REDISCONF="/etc/redis/redis.conf"
			# Allow logstash container to output to redis
			sed -i.bak 's|bind 127.0.0.1|bind 0.0.0.0|g' $REDISCONF
                	ufw allow proto tcp from 172.18.0.0/24 to 172.18.0.1 port 6379 >/dev/null
			# Configure redis memory settings
			TOTAL_MEM=`grep MemTotal /proc/meminfo | awk '{print $2}' | sed -r 's/.{3}$//'`
			REDISMEM=$(($TOTAL_MEM / 10))"m"
			if ! grep "^maxmemory" $REDISCONF >/dev/null 2>&1; then
				sed -i "/# maxmemory <bytes>/ a maxmemory $REDISMEM" $REDISCONF
				sed -i "/# maxmemory-policy volatile-lru/ a maxmemory-policy noeviction" $REDISCONF
			fi
			update-rc.d -f redis-server enable >/dev/null
			service redis-server start >/dev/null
		fi

		# If Elastic auth is enabled, then make sure Logstash is configured to authenticate to Elasticsearch
		if [ -f $ELASTICSEARCH_ACCOUNTS ]; then
		        LOGSTASH_PASSWORD=$(grep "PASSWORD logstash_internal = " $ELASTICSEARCH_ACCOUNTS | awk '{print $4}')
			for i in $LOGSTASH_CONFD/9???_output_*.conf; do
			        if ! grep -q "logstash_internal" $i; then
		        	        chown logstash:logstash $i
			                chmod 640 $i
			                sed -i "s|elasticsearch {|elasticsearch {\n      user => logstash_internal\n      password => \"$LOGSTASH_PASSWORD\"|" $i
			        fi
			done
		fi

		# Publish ports to $LOGSTASH_PUBLISH_IP but control them with iptables rules in DOCKER-USER
                docker run --name=so-logstash \
                        --detach \
			--publish $LOGSTASH_PUBLISH_IP:5044:5044 \
			--publish $LOGSTASH_PUBLISH_IP:6050:6050 \
                        --publish $LOGSTASH_PUBLISH_IP:6051:6051 \
                        --publish $LOGSTASH_PUBLISH_IP:6052:6052 \
                        --publish $LOGSTASH_PUBLISH_IP:6053:6053 \
                        --publish $LOGSTASH_PUBLISH_IP:9600:9600 \
                        --volume /etc/logstash/jvm.options:/usr/share/logstash/config/jvm.options:ro \
			--volume /etc/logstash/log4j2.properties:/usr/share/logstash/config/log4j2.properties:ro \
                        --volume /etc/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro \
                        --volume /etc/logstash/logstash-ossec-template.json:/logstash-ossec-template.json:ro \
                        --volume /etc/logstash/logstash-template.json:/logstash-template.json:ro \
			--volume /etc/logstash/beats-template.json:/beats-template.json:ro \
                        --volume $LOGSTASH_CONFD:/usr/share/logstash/pipeline/:ro \
                        --volume /etc/logstash/conf.d.available/:/usr/share/logstash/conf.d.available/:ro \
                        --volume /etc/nsm/rules:/etc/nsm/rules:ro \
                        --volume /lib/dictionaries:/lib/dictionaries:ro \
                        --volume /nsm/import:/nsm/import:ro \
                        --volume /nsm/logstash:/usr/share/logstash/data/ \
                        --volume /var/log/logstash:/var/log/logstash \
                        --volume /var/log/nsm/securityonion/:/var/log/nsm/securityonion/:ro \
                        $LOGSTASH_OPTIONS \
                        $DOCKERHUB/so-logstash

		# logstash will connect to elasticsearch, domainstats, and freqserver over $DOCKERNET
		docker network connect --alias logstash $DOCKERNET so-logstash
        	
		# Tail log if -v option provided
		if [[ "$TAIL" == 1 ]]; then
			tail -f $LOG
		fi
	fi
fi
